{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1683362510135
        }
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the test data\n",
        "test_defog = pd.read_csv('test/defog/02ab235146.csv')\n",
        "# create a new column for the id which is the filename followed by '_' and the Time\n",
        "test_defog['Id'] = '003f117e14' + '_' + test_defog['Time'].astype(str)\n",
        "test_defog['Source'] = 'defog'\n",
        "\n",
        "test_tdcsfog = pd.read_csv('test/tdcsfog/003f117e14.csv')\n",
        "# create a new column for the id which is '003f117e14' followed by '_' and the Time\n",
        "test_tdcsfog['Id'] = '003f117e14' + '_' + test_tdcsfog['Time'].astype(str)\n",
        "test_tdcsfog['Source'] = 'tdcsfog'\n",
        "\n",
        "# Combine the test data\n",
        "test_data = pd.concat([test_defog, test_tdcsfog], ignore_index=False)\n",
        "# set the index to be 'Unnamed: 0'\n",
        "# test_data['Unnamed: 0'] = test_data.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1683362517360
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def unify_acceleration_units(data):\n",
        "    g_to_ms2 = 9.81\n",
        "\n",
        "    data.loc[data['Source'].isin(['defog', 'notype']), ['AccV', 'AccML', 'AccAP']] *= g_to_ms2\n",
        "    return data\n",
        "\n",
        "test_data = unify_acceleration_units(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AccV</th>\n",
              "      <th>AccML</th>\n",
              "      <th>AccAP</th>\n",
              "      <th>StartHesitation</th>\n",
              "      <th>Turn</th>\n",
              "      <th>Walking</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-9.533939</td>\n",
              "      <td>0.566322</td>\n",
              "      <td>-1.413525</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-9.536140</td>\n",
              "      <td>0.564137</td>\n",
              "      <td>-1.440621</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-9.529345</td>\n",
              "      <td>0.561765</td>\n",
              "      <td>-1.429332</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-9.531239</td>\n",
              "      <td>0.564227</td>\n",
              "      <td>-1.415490</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-9.540825</td>\n",
              "      <td>0.561854</td>\n",
              "      <td>-1.429471</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       AccV     AccML     AccAP  StartHesitation  Turn  Walking\n",
              "0 -9.533939  0.566322 -1.413525              0.0   0.0      0.0\n",
              "1 -9.536140  0.564137 -1.440621              0.0   0.0      0.0\n",
              "2 -9.529345  0.561765 -1.429332              0.0   0.0      0.0\n",
              "3 -9.531239  0.564227 -1.415490              0.0   0.0      0.0\n",
              "4 -9.540825  0.561854 -1.429471              0.0   0.0      0.0"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pro = pd.read_csv('processed.csv')\n",
        "pro.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1683362850601
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "Found 1 mismatches between original and current metadata:\n",
            "\tWARNING: AutoGluon Python version mismatch (original=3.8, current=3.10)\n",
            "Found 1 mismatches between original and current metadata:\n",
            "\tWARNING: AutoGluon Python version mismatch (original=3.8, current=3.10)\n",
            "Found 1 mismatches between original and current metadata:\n",
            "\tWARNING: AutoGluon Python version mismatch (original=3.8, current=3.10)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicting probabilities for StartHesitation...\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "\"2 required columns are missing from the provided dataset to transform using AutoMLPipelineFeatureGenerator. 2 missing columns: ['Turn', 'Walking'] | 6 available columns: ['Time', 'AccV', 'AccML', 'AccAP', 'Id', 'Source']\"",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/autogluon/features/generators/abstract.py:330\u001b[0m, in \u001b[0;36mAbstractFeatureGenerator.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlist\u001b[39m(X\u001b[39m.\u001b[39mcolumns) \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures_in:\n\u001b[1;32m    328\u001b[0m         \u001b[39m# It comes at a cost when making a copy of the DataFrame,\u001b[39;00m\n\u001b[1;32m    329\u001b[0m         \u001b[39m# therefore, try avoid copying by checking the expected features first.\u001b[39;00m\n\u001b[0;32m--> 330\u001b[0m         X \u001b[39m=\u001b[39m X[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeatures_in]\n\u001b[1;32m    331\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/pandas/core/frame.py:3813\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3812\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 3813\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[1;32m   3815\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/pandas/core/indexes/base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6070\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   6072\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/pandas/core/indexes/base.py:6133\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6132\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[0;32m-> 6133\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['Turn', 'Walking'] not in index\"",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPredicting probabilities for \u001b[39m\u001b[39m{\u001b[39;00mlabel\u001b[39m}\u001b[39;00m\u001b[39m...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m predictor \u001b[39m=\u001b[39m predictors[label]\n\u001b[0;32m---> 25\u001b[0m predictions \u001b[39m=\u001b[39m predictor\u001b[39m.\u001b[39;49mpredict((test_data), model\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mWeightedEnsemble_L2\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     26\u001b[0m \u001b[39mprint\u001b[39m(predictions)\n\u001b[1;32m     27\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m(predictions))\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/autogluon/tabular/predictor/predictor.py:1379\u001b[0m, in \u001b[0;36mTabularPredictor.predict\u001b[0;34m(self, data, model, as_pandas, transform_features)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_assert_is_fit(\u001b[39m'\u001b[39m\u001b[39mpredict\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   1378\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_dataset(data)\n\u001b[0;32m-> 1379\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_learner\u001b[39m.\u001b[39;49mpredict(X\u001b[39m=\u001b[39;49mdata, model\u001b[39m=\u001b[39;49mmodel, as_pandas\u001b[39m=\u001b[39;49mas_pandas, transform_features\u001b[39m=\u001b[39;49mtransform_features)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/autogluon/tabular/learner/abstract_learner.py:160\u001b[0m, in \u001b[0;36mAbstractTabularLearner.predict\u001b[0;34m(self, X, model, as_pandas, transform_features)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    159\u001b[0m     X_index \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m y_pred_proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_proba(X\u001b[39m=\u001b[39;49mX, model\u001b[39m=\u001b[39;49mmodel, as_pandas\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, as_multiclass\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, inverse_transform\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, transform_features\u001b[39m=\u001b[39;49mtransform_features)\n\u001b[1;32m    161\u001b[0m problem_type \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabel_cleaner\u001b[39m.\u001b[39mproblem_type_transform \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproblem_type\n\u001b[1;32m    162\u001b[0m y_pred \u001b[39m=\u001b[39m get_pred_from_proba(y_pred_proba\u001b[39m=\u001b[39my_pred_proba, problem_type\u001b[39m=\u001b[39mproblem_type)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/autogluon/tabular/learner/abstract_learner.py:140\u001b[0m, in \u001b[0;36mAbstractTabularLearner.predict_proba\u001b[0;34m(self, X, model, as_pandas, as_multiclass, inverse_transform, transform_features)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    139\u001b[0m     \u001b[39mif\u001b[39;00m transform_features:\n\u001b[0;32m--> 140\u001b[0m         X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform_features(X)\n\u001b[1;32m    141\u001b[0m     y_pred_proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mload_trainer()\u001b[39m.\u001b[39mpredict_proba(X, model\u001b[39m=\u001b[39mmodel)\n\u001b[1;32m    142\u001b[0m \u001b[39mif\u001b[39;00m inverse_transform:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/autogluon/tabular/learner/abstract_learner.py:384\u001b[0m, in \u001b[0;36mAbstractTabularLearner.transform_features\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransform_features\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m    383\u001b[0m     \u001b[39mfor\u001b[39;00m feature_generator \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_generators:\n\u001b[0;32m--> 384\u001b[0m         X \u001b[39m=\u001b[39m feature_generator\u001b[39m.\u001b[39;49mtransform(X)\n\u001b[1;32m    385\u001b[0m     \u001b[39mreturn\u001b[39;00m X\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/autogluon/features/generators/abstract.py:336\u001b[0m, in \u001b[0;36mAbstractFeatureGenerator.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[39mif\u001b[39;00m col \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m X\u001b[39m.\u001b[39mcolumns:\n\u001b[1;32m    335\u001b[0m             missing_cols\u001b[39m.\u001b[39mappend(col)\n\u001b[0;32m--> 336\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(missing_cols)\u001b[39m}\u001b[39;00m\u001b[39m required columns are missing from the provided dataset to transform using \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    337\u001b[0m                    \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(missing_cols)\u001b[39m}\u001b[39;00m\u001b[39m missing columns: \u001b[39m\u001b[39m{\u001b[39;00mmissing_cols\u001b[39m}\u001b[39;00m\u001b[39m | \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    338\u001b[0m                    \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(\u001b[39mlist\u001b[39m(X\u001b[39m.\u001b[39mcolumns))\u001b[39m}\u001b[39;00m\u001b[39m available columns: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(X\u001b[39m.\u001b[39mcolumns)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    339\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pre_astype_generator:\n\u001b[1;32m    340\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pre_astype_generator\u001b[39m.\u001b[39mtransform(X)\n",
            "\u001b[0;31mKeyError\u001b[0m: \"2 required columns are missing from the provided dataset to transform using AutoMLPipelineFeatureGenerator. 2 missing columns: ['Turn', 'Walking'] | 6 available columns: ['Time', 'AccV', 'AccML', 'AccAP', 'Id', 'Source']\""
          ]
        }
      ],
      "source": [
        "from autogluon.tabular import TabularPredictor\n",
        "\n",
        "# Load the saved models\n",
        "predictor_start_hes = TabularPredictor.load('AutogluonModels/start_hes', \n",
        "                                            require_version_match=False,\n",
        "                                            require_py_version_match=False)\n",
        "predictor_turn = TabularPredictor.load('AutogluonModels/turn', \n",
        "                                       require_version_match=False,\n",
        "                                       require_py_version_match=False)\n",
        "predictor_walking = TabularPredictor.load('AutogluonModels/walking', \n",
        "                                          require_version_match=False,\n",
        "                                          require_py_version_match=False)\n",
        "\n",
        "# Make predictions on the test data for each target event type\n",
        "labels = ['StartHesitation', 'Turn', 'Walming']\n",
        "predictors = {\n",
        "    'StartHesitation': predictor_start_hes,\n",
        "    'Turn': predictor_turn,\n",
        "    'Walking': predictor_walking\n",
        "}\n",
        "\n",
        "for label in labels:\n",
        "    print(f\"Predicting probabilities for {label}...\")\n",
        "    predictor = predictors[label]\n",
        "    predictions = predictor.predict((test_data), model='WeightedEnsemble_L2')\n",
        "    print(predictions)\n",
        "    print(type(predictions))\n",
        "\n",
        "# Combine the predictions into a single DataFrame\n",
        "predictions_df = pd.concat(predictions, axis=1)\n",
        "predictions_df.columns = labels\n",
        "print(predictions_df)\n",
        "\n",
        "# Create a new DataFrame with Id and StartHesitation columns\n",
        "predictions_df = pd.DataFrame({\n",
        "    'Id': test_data['Id'],\n",
        "    'StartHesitation': predictions.values\n",
        "})\n",
        "\n",
        "# Save the predictions to a CSV file\n",
        "predictions_df.to_csv('start_hesitation_predictions.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
