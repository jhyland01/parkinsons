{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "filtered_data = pd.read_csv('processed.csv', index_col=False)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into features (X) and targets (y)\n",
        "X = filtered_data.drop(columns=['StartHesitation', 'Turn', 'Walking'])\n",
        "y = filtered_data[['StartHesitation', \n",
        "                   'Turn', \n",
        "                   'Walking',\n",
        "                  ]]\n",
        "\n",
        "# Split the data into training and testing sets (70% training, 30% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Combine the features and targets back into DataFrames for AutoGluon\n",
        "train_data = pd.concat([X_train, y_train], axis=1)\n",
        "test_data = pd.concat([X_test, y_test], axis=1)"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1683234158356
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from autogluon.tabular import TabularDataset, TabularPredictor\n",
        "import gc\n",
        "\n",
        "# Assuming 'train_data' and 'test_data' are DataFrames created from the previous response\n",
        "# Convert the data to AutoGluon's TabularDataset format\n",
        "train_data = TabularDataset(train_data)\n",
        "test_data = TabularDataset(test_data)\n",
        "\n",
        "# Define the target columns\n",
        "labels = ['StartHesitation', 'Turn', 'Walking']\n",
        "\n",
        "# Initialize an empty dictionary to store the predictors\n",
        "predictors = {}\n",
        "\n",
        "# Train a separate regression model for each target event type\n",
        "for label in labels:\n",
        "    print(f\"Training model for {label}...\")\n",
        "    predictor = TabularPredictor(label=label, \n",
        "                                 problem_type='regression', \n",
        "                                 eval_metric='mean_absolute_error',\n",
        "                                 ) # regression with R^2 as the evaluation metric\n",
        "    predictor.fit(train_data, \n",
        "                  num_gpus=1, \n",
        "                  excluded_model_types=['LightGBMLarge'], \n",
        "                  presets=['best_quality']\n",
        "#                   time_limit=600, \n",
        "#                   num_bag_sets = 2, \n",
        "#                   hyperparameters = 'light'\n",
        ")\n",
        "    predictors[label] = predictor\n",
        "\n",
        "# Make predictions on the test data for each target event type\n",
        "predictions = []\n",
        "for label in labels:\n",
        "    print(f\"Predicting probabilities for {label}...\")\n",
        "    predictor = predictors[label]\n",
        "    predictions.append(predictor.predict(test_data.drop(columns=label)))\n",
        "    \n",
        "\n",
        "# Combine the predictions into a single DataFrame\n",
        "predictions_df = pd.DataFrame(predictions)\n",
        "print(predictions_df)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "No path specified. Models will be saved in: \"AutogluonModels/ag-20230504_211354/\"\nPresets specified: ['best_quality']\nStack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\nWarning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (7807241 samples, 437.21 MB).\n\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\nBeginning AutoGluon training ...\nAutoGluon will save models to \"AutogluonModels/ag-20230504_211354/\"\nAutoGluon Version:  0.7.0\nPython Version:     3.10.10\nOperating System:   Linux\nPlatform Machine:   x86_64\nPlatform Version:   #42~20.04.1-Ubuntu SMP Wed Mar 1 19:17:41 UTC 2023\nTrain Data Rows:    7807241\nTrain Data Columns: 5\nLabel Column: StartHesitation\nPreprocessing data ...\nUsing Feature Generators to preprocess the data ...\nFitting AutoMLPipelineFeatureGenerator...\n\tAvailable Memory:                    40667.99 MB\n\tTrain Data (Original)  Memory Usage: 312.29 MB (0.8% of available memory)\n\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n\tStage 1 Generators:\n\t\tFitting AsTypeFeatureGenerator...\n\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n\tStage 2 Generators:\n\t\tFitting FillNaFeatureGenerator...\n\tStage 3 Generators:\n\t\tFitting IdentityFeatureGenerator...\n\tStage 4 Generators:\n\t\tFitting DropUniqueFeatureGenerator...\n\tTypes of features in original data (raw dtype, special dtypes):\n\t\t('float', []) : 5 | ['AccV', 'AccML', 'AccAP', 'Turn', 'Walking']\n\tTypes of features in processed data (raw dtype, special dtypes):\n\t\t('float', [])     : 3 | ['AccV', 'AccML', 'AccAP']\n\t\t('int', ['bool']) : 2 | ['Turn', 'Walking']\n\t20.3s = Fit runtime\n\t5 features in original data used to generate 5 features in processed data.\n\tTrain Data (Processed) Memory Usage: 202.99 MB (0.5% of available memory)\nData preprocessing and feature engineering runtime = 21.31s ...\nAutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n\tTo change this, specify the eval_metric parameter of Predictor()\nAutoGluon will fit 2 stack levels (L1 to L2) ...\nExcluded Model Types: ['LightGBMLarge']\nFitting 11 L1 models ...\nFitting model: KNeighborsUnif_BAG_L1 ...\n\t-0.0477\t = Validation score   (-mean_absolute_error)\n\t16.4s\t = Training   runtime\n\t59.37s\t = Validation runtime\nFitting model: KNeighborsDist_BAG_L1 ...\n\t-0.0477\t = Validation score   (-mean_absolute_error)\n\t16.22s\t = Training   runtime\n\t47.9s\t = Validation runtime\nFitting model: LightGBMXT_BAG_L1 ...\n\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Training model for StartHesitation...\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1683234811245
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}