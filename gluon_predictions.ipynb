{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the test data\n",
    "test_defog = pd.read_csv('test/defog/02ab235146.csv')\n",
    "# create a new column for the id which is the filename followed by '_' and the Time\n",
    "test_defog['Id'] = '003f117e14' + '_' + test_defog['Time'].astype(str)\n",
    "test_defog['Source'] = 'defog'\n",
    "\n",
    "test_tdcsfog = pd.read_csv('test/tdcsfog/003f117e14.csv')\n",
    "# create a new column for the id which is '003f117e14' followed by '_' and the Time\n",
    "test_tdcsfog['Id'] = '003f117e14' + '_' + test_tdcsfog['Time'].astype(str)\n",
    "test_tdcsfog['Source'] = 'tdcsfog'\n",
    "\n",
    "# Combine the test data\n",
    "test_data = pd.concat([test_defog, test_tdcsfog], ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def unify_sampling_rate(data):\n",
    "    # Interpolate defog and notype data from 100Hz to 128Hz\n",
    "    def interpolate_data(df):\n",
    "        df['Time'] = pd.to_timedelta(df['Time'], unit='ms')  # Convert 'Time' column to timedelta\n",
    "        df_resampled = df.set_index('Time').resample('7.8125ms').interpolate(method='linear').reset_index()\n",
    "        return df_resampled\n",
    "\n",
    "    data_defog = data[data['Source'].isin(['defog', 'notype'])].groupby('SeriesId').apply(interpolate_data).reset_index(drop=True)\n",
    "    data_tdcsfog = data[data['Source'] == 'tdcsfog']\n",
    "\n",
    "    unified_data = pd.concat([data_tdcsfog, data_defog], ignore_index=True)\n",
    "    return unified_data\n",
    "\n",
    "\n",
    "def unify_acceleration_units(data):\n",
    "    g_to_ms2 = 9.81\n",
    "\n",
    "    data.loc[data['Source'].isin(['defog', 'notype']), ['AccV', 'AccML', 'AccAP']] *= g_to_ms2\n",
    "    return data\n",
    "\n",
    "def filter_data(data):\n",
    "    filtered_data = data[(data['Valid'].fillna(True)) & (data['Task'].fillna(True))].reset_index(drop=True)\n",
    "    return filtered_data\n",
    "\n",
    "# test_data = unify_sampling_rate(test_data)\n",
    "test_data = unify_acceleration_units(test_data)\n",
    "test_data['Unnamed: 0'] = test_data['Time']\n",
    "# filtered_test_data = filter_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>AccV</th>\n",
       "      <th>AccML</th>\n",
       "      <th>AccAP</th>\n",
       "      <th>Id</th>\n",
       "      <th>Source</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-8.972738</td>\n",
       "      <td>-2.951349</td>\n",
       "      <td>2.924906</td>\n",
       "      <td>003f117e14_0</td>\n",
       "      <td>defog</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-8.969944</td>\n",
       "      <td>-2.958421</td>\n",
       "      <td>2.926564</td>\n",
       "      <td>003f117e14_1</td>\n",
       "      <td>defog</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-7.647290</td>\n",
       "      <td>-3.366763</td>\n",
       "      <td>2.704516</td>\n",
       "      <td>003f117e14_2</td>\n",
       "      <td>defog</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-9.742921</td>\n",
       "      <td>-2.651460</td>\n",
       "      <td>3.097750</td>\n",
       "      <td>003f117e14_3</td>\n",
       "      <td>defog</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-9.307401</td>\n",
       "      <td>-3.019995</td>\n",
       "      <td>2.915445</td>\n",
       "      <td>003f117e14_4</td>\n",
       "      <td>defog</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time      AccV     AccML     AccAP            Id Source  Unnamed: 0\n",
       "0     0 -8.972738 -2.951349  2.924906  003f117e14_0  defog           0\n",
       "1     1 -8.969944 -2.958421  2.926564  003f117e14_1  defog           1\n",
       "2     2 -7.647290 -3.366763  2.704516  003f117e14_2  defog           2\n",
       "3     3 -9.742921 -2.651460  3.097750  003f117e14_3  defog           3\n",
       "4     4 -9.307401 -3.019995  2.915445  003f117e14_4  defog           4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "############################## WARNING ##############################\n",
      "WARNING: AutoGluon version differs from the version used to create the predictor! This may lead to instability and it is highly recommended the predictor be loaded with the exact AutoGluon version it was created with.\n",
      "\tPredictor Version: 0.6.2\n",
      "\tCurrent Version:   0.7.0\n",
      "############################## WARNING ##############################\n",
      "\n",
      "Found 3 mismatches between original and current metadata:\n",
      "\tWARNING: AutoGluon version mismatch (original=0.6.2, current=0.7.0)\n",
      "\tWARNING: AutoGluon Python version mismatch (original=3.7, current=3.10)\n",
      "\tWARNING: System mismatch (original=Linux, current=Darwin)\n",
      "\n",
      "############################## WARNING ##############################\n",
      "WARNING: AutoGluon version differs from the version used to create the predictor! This may lead to instability and it is highly recommended the predictor be loaded with the exact AutoGluon version it was created with.\n",
      "\tPredictor Version: 0.6.2\n",
      "\tCurrent Version:   0.7.0\n",
      "############################## WARNING ##############################\n",
      "\n",
      "Found 3 mismatches between original and current metadata:\n",
      "\tWARNING: AutoGluon version mismatch (original=0.6.2, current=0.7.0)\n",
      "\tWARNING: AutoGluon Python version mismatch (original=3.7, current=3.10)\n",
      "\tWARNING: System mismatch (original=Linux, current=Darwin)\n",
      "\n",
      "############################## WARNING ##############################\n",
      "WARNING: AutoGluon version differs from the version used to create the predictor! This may lead to instability and it is highly recommended the predictor be loaded with the exact AutoGluon version it was created with.\n",
      "\tPredictor Version: 0.6.2\n",
      "\tCurrent Version:   0.7.0\n",
      "############################## WARNING ##############################\n",
      "\n",
      "Found 3 mismatches between original and current metadata:\n",
      "\tWARNING: AutoGluon version mismatch (original=0.6.2, current=0.7.0)\n",
      "\tWARNING: AutoGluon Python version mismatch (original=3.7, current=3.10)\n",
      "\tWARNING: System mismatch (original=Linux, current=Darwin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting probabilities for StartHesitation...\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearnex'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/johnny/Library/CloudStorage/OneDrive-Personal/py/Kaggle/parkinsons/gluon_predictions.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/johnny/Library/CloudStorage/OneDrive-Personal/py/Kaggle/parkinsons/gluon_predictions.ipynb#W3sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPredicting probabilities for \u001b[39m\u001b[39m{\u001b[39;00mlabel\u001b[39m}\u001b[39;00m\u001b[39m...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/johnny/Library/CloudStorage/OneDrive-Personal/py/Kaggle/parkinsons/gluon_predictions.ipynb#W3sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     predictor \u001b[39m=\u001b[39m predictors[label]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/johnny/Library/CloudStorage/OneDrive-Personal/py/Kaggle/parkinsons/gluon_predictions.ipynb#W3sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     predictions\u001b[39m.\u001b[39mappend(predictor\u001b[39m.\u001b[39;49mpredict(test_data), model\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mWeightedEnsemble_L2\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/johnny/Library/CloudStorage/OneDrive-Personal/py/Kaggle/parkinsons/gluon_predictions.ipynb#W3sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# Combine the predictions into a single DataFrame\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/johnny/Library/CloudStorage/OneDrive-Personal/py/Kaggle/parkinsons/gluon_predictions.ipynb#W3sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m predictions_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat(predictions, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kaggle/lib/python3.10/site-packages/autogluon/tabular/predictor/predictor.py:1379\u001b[0m, in \u001b[0;36mTabularPredictor.predict\u001b[0;34m(self, data, model, as_pandas, transform_features)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_assert_is_fit(\u001b[39m'\u001b[39m\u001b[39mpredict\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   1378\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_dataset(data)\n\u001b[0;32m-> 1379\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_learner\u001b[39m.\u001b[39;49mpredict(X\u001b[39m=\u001b[39;49mdata, model\u001b[39m=\u001b[39;49mmodel, as_pandas\u001b[39m=\u001b[39;49mas_pandas, transform_features\u001b[39m=\u001b[39;49mtransform_features)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kaggle/lib/python3.10/site-packages/autogluon/tabular/learner/abstract_learner.py:160\u001b[0m, in \u001b[0;36mAbstractTabularLearner.predict\u001b[0;34m(self, X, model, as_pandas, transform_features)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    159\u001b[0m     X_index \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m y_pred_proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_proba(X\u001b[39m=\u001b[39;49mX, model\u001b[39m=\u001b[39;49mmodel, as_pandas\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, as_multiclass\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, inverse_transform\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, transform_features\u001b[39m=\u001b[39;49mtransform_features)\n\u001b[1;32m    161\u001b[0m problem_type \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabel_cleaner\u001b[39m.\u001b[39mproblem_type_transform \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproblem_type\n\u001b[1;32m    162\u001b[0m y_pred \u001b[39m=\u001b[39m get_pred_from_proba(y_pred_proba\u001b[39m=\u001b[39my_pred_proba, problem_type\u001b[39m=\u001b[39mproblem_type)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kaggle/lib/python3.10/site-packages/autogluon/tabular/learner/abstract_learner.py:141\u001b[0m, in \u001b[0;36mAbstractTabularLearner.predict_proba\u001b[0;34m(self, X, model, as_pandas, as_multiclass, inverse_transform, transform_features)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[39mif\u001b[39;00m transform_features:\n\u001b[1;32m    140\u001b[0m         X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform_features(X)\n\u001b[0;32m--> 141\u001b[0m     y_pred_proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload_trainer()\u001b[39m.\u001b[39;49mpredict_proba(X, model\u001b[39m=\u001b[39;49mmodel)\n\u001b[1;32m    142\u001b[0m \u001b[39mif\u001b[39;00m inverse_transform:\n\u001b[1;32m    143\u001b[0m     y_pred_proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabel_cleaner\u001b[39m.\u001b[39minverse_transform_proba(y_pred_proba)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kaggle/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py:567\u001b[0m, in \u001b[0;36mAbstractTrainer.predict_proba\u001b[0;34m(self, X, model)\u001b[0m\n\u001b[1;32m    565\u001b[0m     model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_best()\n\u001b[1;32m    566\u001b[0m cascade \u001b[39m=\u001b[39m \u001b[39misinstance\u001b[39m(model, \u001b[39mlist\u001b[39m)\n\u001b[0;32m--> 567\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predict_proba_model(X, model, cascade\u001b[39m=\u001b[39;49mcascade)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kaggle/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py:2062\u001b[0m, in \u001b[0;36mAbstractTrainer._predict_proba_model\u001b[0;34m(self, X, model, model_pred_proba_dict, cascade)\u001b[0m\n\u001b[1;32m   2061\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_predict_proba_model\u001b[39m(\u001b[39mself\u001b[39m, X, model, model_pred_proba_dict\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, cascade\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m-> 2062\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_pred_proba_from_model(model\u001b[39m=\u001b[39;49mmodel, X\u001b[39m=\u001b[39;49mX, model_pred_proba_dict\u001b[39m=\u001b[39;49mmodel_pred_proba_dict, cascade\u001b[39m=\u001b[39;49mcascade)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kaggle/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py:581\u001b[0m, in \u001b[0;36mAbstractTrainer.get_pred_proba_from_model\u001b[0;34m(self, model, X, model_pred_proba_dict, cascade)\u001b[0m\n\u001b[1;32m    579\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    580\u001b[0m     models \u001b[39m=\u001b[39m [model]\n\u001b[0;32m--> 581\u001b[0m model_pred_proba_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_model_pred_proba_dict(X\u001b[39m=\u001b[39;49mX, models\u001b[39m=\u001b[39;49mmodels, model_pred_proba_dict\u001b[39m=\u001b[39;49mmodel_pred_proba_dict, cascade\u001b[39m=\u001b[39;49mcascade)\n\u001b[1;32m    582\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(model, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    583\u001b[0m     model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mname\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kaggle/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py:807\u001b[0m, in \u001b[0;36mAbstractTrainer.get_model_pred_proba_dict\u001b[0;34m(self, X, models, model_pred_proba_dict, model_pred_time_dict, record_pred_time, use_val_cache, cascade, cascade_threshold)\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[39mif\u001b[39;00m cascade:\n\u001b[1;32m    804\u001b[0m     \u001b[39m# Keep track of the iloc index of the current model for the rows that are predicted on.\u001b[39;00m\n\u001b[1;32m    805\u001b[0m     \u001b[39m#  iloc is used because it is a very compute efficient way to track the location of rows.\u001b[39;00m\n\u001b[1;32m    806\u001b[0m     iloc_model_dict[model_name] \u001b[39m=\u001b[39m unconfident_idx\n\u001b[0;32m--> 807\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload_model(model_name\u001b[39m=\u001b[39;49mmodel_name)\n\u001b[1;32m    808\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(model, StackerEnsembleModel):\n\u001b[1;32m    809\u001b[0m     \u001b[39mif\u001b[39;00m cascade:\n\u001b[1;32m    810\u001b[0m         \u001b[39m# Need to predict only on the unconfident rows that remain.\u001b[39;00m\n\u001b[1;32m    811\u001b[0m         \u001b[39m#  This requires getting the correct indices from the dependent models' prior predictions.\u001b[39;00m\n\u001b[1;32m    812\u001b[0m         \u001b[39m#  Because the length of predictions in prior models differs due to early exiting,\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[39m#  this logic fetches the correct indices via the iloc_model_dict.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kaggle/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py:1352\u001b[0m, in \u001b[0;36mAbstractTrainer.load_model\u001b[0;34m(self, model_name, path, model_type)\u001b[0m\n\u001b[1;32m   1350\u001b[0m \u001b[39mif\u001b[39;00m model_type \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1351\u001b[0m     model_type \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_model_attribute(model\u001b[39m=\u001b[39mmodel_name, attribute\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 1352\u001b[0m \u001b[39mreturn\u001b[39;00m model_type\u001b[39m.\u001b[39;49mload(path\u001b[39m=\u001b[39;49mpath, reset_paths\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreset_paths)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kaggle/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py:926\u001b[0m, in \u001b[0;36mAbstractModel.load\u001b[0;34m(cls, path, reset_paths, verbose)\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    905\u001b[0m \u001b[39mLoads the model from disk to memory.\u001b[39;00m\n\u001b[1;32m    906\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[39m    Loaded model object.\u001b[39;00m\n\u001b[1;32m    924\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    925\u001b[0m file_path \u001b[39m=\u001b[39m path \u001b[39m+\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mmodel_file_name\n\u001b[0;32m--> 926\u001b[0m model \u001b[39m=\u001b[39m load_pkl\u001b[39m.\u001b[39;49mload(path\u001b[39m=\u001b[39;49mfile_path, verbose\u001b[39m=\u001b[39;49mverbose)\n\u001b[1;32m    927\u001b[0m \u001b[39mif\u001b[39;00m reset_paths:\n\u001b[1;32m    928\u001b[0m     model\u001b[39m.\u001b[39mset_contexts(path)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kaggle/lib/python3.10/site-packages/autogluon/common/loaders/load_pkl.py:43\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, format, verbose, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39mif\u001b[39;00m compression_fn \u001b[39min\u001b[39;00m compression_fn_map:\n\u001b[1;32m     42\u001b[0m     \u001b[39mwith\u001b[39;00m compression_fn_map[compression_fn][\u001b[39m'\u001b[39m\u001b[39mopen\u001b[39m\u001b[39m'\u001b[39m](validated_path, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcompression_fn_kwargs) \u001b[39mas\u001b[39;00m fin:\n\u001b[0;32m---> 43\u001b[0m         \u001b[39mobject\u001b[39m \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39;49mload(fin)\n\u001b[1;32m     44\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     45\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     46\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcompression_fn=\u001b[39m\u001b[39m{\u001b[39;00mcompression_fn\u001b[39m}\u001b[39;00m\u001b[39m or compression_fn_kwargs=\u001b[39m\u001b[39m{\u001b[39;00mcompression_fn_kwargs\u001b[39m}\u001b[39;00m\u001b[39m are not valid.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     47\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m Valid function values: \u001b[39m\u001b[39m{\u001b[39;00mcompression_fn_map\u001b[39m.\u001b[39mkeys()\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearnex'"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "# Load the saved models\n",
    "predictor_start_hes = TabularPredictor.load('AutogluonModels/start_hes', \n",
    "                                            require_version_match=False,\n",
    "                                            require_py_version_match=False)\n",
    "predictor_turn = TabularPredictor.load('AutogluonModels/turn', \n",
    "                                       require_version_match=False,\n",
    "                                       require_py_version_match=False)\n",
    "predictor_walking = TabularPredictor.load('AutogluonModels/walking', \n",
    "                                          require_version_match=False,\n",
    "                                          require_py_version_match=False)\n",
    "\n",
    "# Make predictions on the test data for each target event type\n",
    "predictions = []\n",
    "labels = ['StartHesitation', 'Turn', 'Walking']\n",
    "predictors = {\n",
    "    'StartHesitation': predictor_start_hes,\n",
    "    'Turn': predictor_turn,\n",
    "    'Walking': predictor_walking\n",
    "}\n",
    "\n",
    "for label in labels:\n",
    "    print(f\"Predicting probabilities for {label}...\")\n",
    "    predictor = predictors[label]\n",
    "    predictions.append(predictor.predict(test_data), model='WeightedEnsemble_L2')\n",
    "\n",
    "# Combine the predictions into a single DataFrame\n",
    "predictions_df = pd.concat(predictions, axis=1)\n",
    "predictions_df.columns = labels\n",
    "print(predictions_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
